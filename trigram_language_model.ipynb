{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c314576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1e2208f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = open('animals.txt', 'r').read().splitlines()\n",
    "animals = [a.lower() for a in animals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "01aed209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['canidae',\n",
       " 'felidae',\n",
       " 'cat',\n",
       " 'cattle',\n",
       " 'dog',\n",
       " 'donkey',\n",
       " 'goat',\n",
       " 'guinea pig',\n",
       " 'horse',\n",
       " 'pig']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a90c16f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of animal names: 520\n",
      "Min animal name size: 2\n",
      "Max animal name size: 33\n"
     ]
    }
   ],
   "source": [
    "print('Number of animal names:', len(animals))\n",
    "print('Min animal name size:', min(len(a) for a in animals))\n",
    "print('Max animal name size:', max(len(a) for a in animals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "71fa2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dictionary of trigrams from animal names\n",
    "b = {}\n",
    "for a in animals:\n",
    "    chs = list(a) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        trigram = (ch1, ch2, ch3)\n",
    "        b[trigram] = b.get(trigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "08222200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(b.items(), key = lambda kv: -kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "937e0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(animals)))) # list of characters used\n",
    "stoi = {s: i+1 for i,s in enumerate(chars)} # mapping string to index\n",
    "stoi['.'] = 0 # end character\n",
    "itos = {i: s for s,i in stoi.items()} # mapping index to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fabc5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the traning set of all the trigrams\n",
    "xs, ys = [], []\n",
    "for a in animals:\n",
    "    chs = ['.'] + list(a) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs.append([ix1, ix2])\n",
    "        ys.append(ix3)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num_examples = xs.nelement() // 2\n",
    "num_classes = len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d827ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of traning examples: 4056\n",
      "Size of traning data: torch.Size([4056, 2])\n",
      "Size of target data: torch.Size([4056])\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of traning examples: {num_examples}')\n",
    "print(f'Size of traning data: {xs.shape}')\n",
    "print(f'Size of target data: {ys.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "87c69a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the one=hot encodings into a single vector\n",
    "x_one_hot = F.one_hot(xs, num_classes=num_classes).float()\n",
    "x_one_hot = x_one_hot.view(num_examples, -1)  # shape: [num_examples, 2*num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ed99b6ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data: torch.Size([4056, 56])\n"
     ]
    }
   ],
   "source": [
    "# Each row of the matrix represents a bigram encoded\n",
    "# Each digit of the biagram are 28 bits or num_classes bits\n",
    "print(f'Shape of input data: {x_one_hot.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "08205c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix of weights: torch.Size([56, 28])\n"
     ]
    }
   ],
   "source": [
    "# Initialize a single weight matrix\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W =  torch.randn((2*num_classes, num_classes), generator=g, requires_grad=True)\n",
    "print(f'Shape of matrix of weights: {W.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "47a0964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4056, 28])\n",
      "2.152465581893921\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "for k in range(1):\n",
    "    # Forward pass\n",
    "    logits = x_one_hot @ W  # shape: [num_examples, num_classes]\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True) # normalize each row\n",
    "    loss = -probs[torch.arange(num_examples), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "00e8679f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctoick\n",
      "hor bug\n",
      "orkey falamperh\n",
      "musnorot\n",
      "estal\n",
      "chees bueank\n",
      "ug briac haly la\n",
      "crine\n",
      "mat\n",
      "ansaneerttlighendst\n",
      "iloommate par fiste\n",
      "carrdoneestir wh\n",
      "macel\n",
      "hel\n",
      "xermos\n",
      "hormorinal\n",
      "ory gecrnieloss\n",
      "fow\n",
      "heethee\n",
      "canshimmalk\n",
      "hore\n",
      "earo\n",
      "aid midangutar\n",
      "arous\n",
      "file\n",
      "arickgieerss\n",
      "oook\n",
      "orato\n",
      "hinh\n",
      "allionsa\n",
      "ygulaluspids\n",
      "ea\n",
      "manickowlamshomer h\n",
      "oufinetroal\n",
      "ela\n",
      "ardoot\n",
      "hod wh\n",
      "vile\n",
      "ernc dorcyingank\n",
      "hourfil\n",
      "haraverk\n",
      "pardvepdgurk\n",
      "nounnac matticla\n",
      "varramacarmeom\n",
      "moneadse\n",
      "arifarmee babbatuin\n",
      "olint\n",
      "maider bus\n",
      "erockaidoppyindrec \n",
      "fosturkangratfish\n"
     ]
    }
   ],
   "source": [
    "# Finally, we sample from the neural net model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(50):\n",
    "    out = ['.']\n",
    "    ix = 0\n",
    "    while True:\n",
    "        # Prepare the input from the last two characters\n",
    "        if len(out) > 1:\n",
    "            ix1, ix2 = stoi[out[-2]], stoi[out[-1]]  # Last two characters\n",
    "        else:\n",
    "            ix1, ix2 = stoi['.'], stoi[out[-1]]  # Use '.' if only one character has been generated\n",
    "        \n",
    "        # Create one-hot encoding for the concatenated last two characters\n",
    "        xenc1 = F.one_hot(torch.tensor([ix1]), num_classes=num_classes).float()\n",
    "        xenc2 = F.one_hot(torch.tensor([ix2]), num_classes=num_classes).float()\n",
    "        xenc = torch.cat((xenc1, xenc2), dim=-1)  # Concatenate the encodings\n",
    "        \n",
    "        # Generate logits for the next character\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdim=True)\n",
    "        \n",
    "        # Sample the next character\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        \n",
    "        # Break if the end token is generated or length exceeds a limit (e.g., to avoid infinite loops)\n",
    "        if ix == 0 or len(out) > 20:  # Adjust the length limit as needed\n",
    "            break\n",
    "    \n",
    "    # Print the generated word, excluding the start/end token\n",
    "    print(''.join(out[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b283e176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
